
import numpy as np
import cvxpy as cp
from scipy.linalg import inv
import pickle
import sys
import os
from scipy.io import loadmat
try:
    from oct2py import Oct2Py
    HAS_OCT2PY = True
except ImportError:
    print("âš ï¸  è­¦å‘Š: oct2py æœªå®‰è£…ã€‚å°†ä½¿ç”¨çº¯Pythonç‰ˆæœ¬ï¼ˆè¾ƒæ…¢ï¼‰")
    HAS_OCT2PY = False
import h5py
def friction_regressor_single(qd):
    """
    Y_frctn: æ‘©æ“¦å›å½’çŸ©é˜µ (6, 18)
    """
    Y_frctn = np.zeros((6, 18))
    
    for i in range(6):
        # æ¯ä¸ªå…³èŠ‚3ä¸ªæ‘©æ“¦å‚æ•°: [ç²˜æ€§, åº“ä¼¦, å¸¸æ•°]
        Y_frctn[i, 3*i:3*i+3] = [
            qd[i],           # ç²˜æ€§æ‘©æ“¦
            np.sign(qd[i]),  # åº“ä¼¦æ‘©æ“¦
            1.0              # å¸¸æ•°é¡¹
        ]
    
    return Y_frctn


def friction_regressor_batched(qd_matrix):
    """
    
    Args:
        qd_matrix: å…³èŠ‚é€Ÿåº¦çŸ©é˜µ (N, 6)
    
    Returns:
        Y_frctn_total: æ‘©æ“¦å›å½’çŸ©é˜µ (6N, 18)
    """
    N = qd_matrix.shape[0]
    Y_frctn_total = np.zeros((N * 6, 18))
    
    for i in range(N):
        Y_frctn_i = friction_regressor_single(qd_matrix[i, :])
        Y_frctn_total[i*6:(i+1)*6, :] = Y_frctn_i
    
    return Y_frctn_total



def build_observation_matrices_oct2py(idntfcn_traj, baseQR, drv_gains):
    """
    ä½¿ç”¨Oct2Pyè°ƒç”¨MATLABå‡½æ•°æ„å»ºè§‚æµ‹çŸ©é˜µ
    
    Args:
        idntfcn_traj: è½¨è¿¹æ•°æ®å­—å…¸
        baseQR: QRåˆ†è§£ç»“æœ
        drv_gains: é©±åŠ¨å¢ç›Š
    
    Returns:
        Tau: åŠ›çŸ©å‘é‡ (6N,)
        Wb: è§‚æµ‹çŸ©é˜µ (6N, n_base + 18)
    """
    print("  ä½¿ç”¨Oct2Pyæ–¹æ³•æ„å»ºè§‚æµ‹çŸ©é˜µ...")
    
    oc = Oct2Py()
    oc.addpath('autogen')  # æ·»åŠ MATLABå‡½æ•°è·¯å¾„
    oc.addpath('matlab')   # å¦‚æœæœ‰å…¶ä»–è·¯å¾„
    oc.addpath('.')        # å½“å‰ç›®å½•
    
    # å‡†å¤‡æ•°æ®
    q_matrix = idntfcn_traj['q']
    qd_fltrd_matrix = idntfcn_traj['qd_fltrd']
    q2d_est_matrix = idntfcn_traj['q2d_est']
    Tau_matrix = idntfcn_traj['i_fltrd']
    n_samples = q_matrix.shape[0]
    
    try:
        # å°è¯•è°ƒç”¨æ‰¹é‡å‡½æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        Y_std_total = oc.standard_regressor_airbot_batched(
            q_matrix, qd_fltrd_matrix, q2d_est_matrix
        )
    except:
        Y_std_list = []
        
        for i in range(n_samples):
            if (i + 1) % 200 == 0:
                print(f"      è¿›åº¦: {i+1}/{n_samples}")
            
            q_col = q_matrix[i, :].reshape(-1, 1)
            qd_col = qd_fltrd_matrix[i, :].reshape(-1, 1)
            qdd_col = q2d_est_matrix[i, :].reshape(-1, 1)
            
            Yi = oc.standard_regressor_airbot(q_col, qd_col, qdd_col)
            Y_std_list.append(Yi)
        
        Y_std_total = np.vstack(Y_std_list)
    
    # è®¡ç®—æ‘©æ“¦å›å½’çŸ©é˜µ
    print("    è®¡ç®—æ‘©æ“¦å›å½’çŸ©é˜µ...")
    Y_frctn_total = friction_regressor_batched(qd_fltrd_matrix)
    
    # æ„å»ºåŸºç¡€è§‚æµ‹çŸ©é˜µ
    n_base = baseQR['numberOfBaseParameters']
    E_full = baseQR['permutationMatrixFull']
    E1 = E_full[:, :n_base]
    
    W_dyn = Y_std_total @ E1
    Wb = np.hstack([W_dyn, Y_frctn_total])
    
    # åŠ›çŸ©å‘é‡
    Tau = Tau_matrix.flatten()
    
    # æ¸…ç†
    oc.exit()
    
    print(f"  âœ“ è§‚æµ‹çŸ©é˜µæ„å»ºå®Œæˆ: {Wb.shape}")
    
    return Tau, Wb



def build_observation_matrices_python(idntfcn_traj, baseQR, drv_gains):
    """
    
    Args:
        idntfcn_traj: è½¨è¿¹æ•°æ®å­—å…¸
        baseQR: QRåˆ†è§£ç»“æœ
        drv_gains: é©±åŠ¨å¢ç›Š
    
    Returns:
        Tau: åŠ›çŸ©å‘é‡ (6N,)
        Wb: è§‚æµ‹çŸ©é˜µ (6N, n_base + 18)
    """
    print("  ä½¿ç”¨çº¯Pythonæ–¹æ³•æ„å»ºè§‚æµ‹çŸ©é˜µ...")
    
    # å°è¯•å¯¼å…¥Pythonç‰ˆæœ¬çš„regressor
    try:
        sys.path.insert(0, 'matlab')
        sys.path.insert(0, 'autogen')
        from standard_regressor_airbot import standard_regressor_airbot
        print("    âœ“ æˆåŠŸå¯¼å…¥Pythonç‰ˆæœ¬çš„standard_regressor_airbot")
    except ImportError:
        raise ImportError(
            "æ— æ³•å¯¼å…¥standard_regressor_airbotå‡½æ•°ã€‚\n"
            "è¯·å…ˆè¿è¡Œ generate_rb_regressor_complete.py ç”ŸæˆPythonå‡½æ•°ï¼Œ\n"
            "æˆ–å®‰è£… oct2py ä½¿ç”¨MATLABå‡½æ•°ã€‚"
        )
    
    # å‡†å¤‡æ•°æ®
    q_matrix = idntfcn_traj['q']
    qd_fltrd_matrix = idntfcn_traj['qd_fltrd']
    q2d_est_matrix = idntfcn_traj['q2d_est']
    Tau_matrix = idntfcn_traj['i_fltrd']
    n_samples = q_matrix.shape[0]
    
    print(f"    å¤„ç† {n_samples} ä¸ªæ ·æœ¬...")
    
    # é€ä¸ªè®¡ç®—æ ‡å‡†å›å½’çŸ©é˜µ
    Y_std_list = []
    for i in range(n_samples):
        if (i + 1) % 200 == 0:
            print(f"      è¿›åº¦: {i+1}/{n_samples}")
        
        Yi = standard_regressor_airbot(
            *q_matrix[i, :],
            *qd_fltrd_matrix[i, :],
            *q2d_est_matrix[i, :]
        )
        Y_std_list.append(Yi)
    
    Y_std_total = np.vstack(Y_std_list)
    
    # è®¡ç®—æ‘©æ“¦å›å½’çŸ©é˜µ
    print("    è®¡ç®—æ‘©æ“¦å›å½’çŸ©é˜µ...")
    Y_frctn_total = friction_regressor_batched(qd_fltrd_matrix)
    
    # æ„å»ºåŸºç¡€è§‚æµ‹çŸ©é˜µ
    n_base = baseQR['numberOfBaseParameters']
    E_full = baseQR['permutationMatrixFull']
    E1 = E_full[:, :n_base]
    
    W_dyn = Y_std_total @ E1
    Wb = np.hstack([W_dyn, Y_frctn_total])
    
    # åŠ›çŸ©å‘é‡
    Tau = Tau_matrix.flatten()
    
    print(f"  âœ“ è§‚æµ‹çŸ©é˜µæ„å»ºå®Œæˆ: {Wb.shape}")
    
    return Tau, Wb



def build_observation_matrices(idntfcn_traj, baseQR, drv_gains):
    """
    Returns:
        Tau: åŠ›çŸ©å‘é‡ (6N,)
        Wb: è§‚æµ‹çŸ©é˜µ (6N, n_base + 18)
    """
    if HAS_OCT2PY:
        try:
            return build_observation_matrices_oct2py(idntfcn_traj, baseQR, drv_gains)
        except Exception as e:
            print(f"  âš ï¸  Oct2Pyæ–¹æ³•å¤±è´¥: {e}")
            print("  å›é€€åˆ°çº¯Pythonæ–¹æ³•...")
            return build_observation_matrices_python(idntfcn_traj, baseQR, drv_gains)
    else:
        return build_observation_matrices_python(idntfcn_traj, baseQR, drv_gains)


# æ±‚è§£å™¨

def ordinary_least_square_estimation(Tau, Wb, baseQR):
    """æ™®é€šæœ€å°äºŒä¹˜ä¼°è®¡"""
    print("  ä½¿ç”¨æ™®é€šæœ€å°äºŒä¹˜æ³•...")
    
    pi_OLS = np.linalg.lstsq(Wb, Tau, rcond=None)[0]
    
    n_b = baseQR['numberOfBaseParameters']
    pi_b_OLS = pi_OLS[:n_b]
    pi_frctn_OLS = pi_OLS[n_b:]
    
    print(f"  âœ“ ä¼°è®¡äº† {n_b} ä¸ªåŸºç¡€å‚æ•°å’Œ {len(pi_frctn_OLS)} ä¸ªæ‘©æ“¦å‚æ•°")
    return pi_b_OLS, pi_frctn_OLS


def physically_consistent_estimation(Tau, Wb, baseQR, pi_urdf=None, lambda_reg=0):
    """
    ç‰©ç†ä¸€è‡´æ€§å‚æ•°ä¼°è®¡
    
    Args:
        Tau: åŠ›çŸ©å‘é‡
        Wb: è§‚æµ‹çŸ©é˜µ
        baseQR: QRåˆ†è§£ç»“æœ
        pi_urdf: URDFå‚è€ƒå‚æ•°ï¼ˆå‰5ä¸ªlinkï¼Œ50ç»´ï¼‰
        lambda_reg: æ­£åˆ™åŒ–ç³»æ•°
    """
    print("  ä½¿ç”¨ç‰©ç†ä¸€è‡´æ€§çº¦æŸä¼˜åŒ–...")
    
    # å‚æ•°è®¾ç½®
    n_b = baseQR['numberOfBaseParameters']
    n_d = 60 - n_b
    
    print(f"    åŸºç¡€å‚æ•°: {n_b}, ä¾èµ–å‚æ•°: {n_d}")
    
    # å®šä¹‰ä¼˜åŒ–å˜é‡
    pi_frctn = cp.Variable(18)
    pi_b = cp.Variable(n_b)
    pi_d = cp.Variable(n_d)
    
    # æ˜ å°„åˆ°æ ‡å‡†å‚æ•°
    mapping_matrix = np.block([
        [np.eye(n_b), -baseQR['beta']],
        [np.zeros((n_d, n_b)), np.eye(n_d)]
    ])
    E = baseQR['permutationMatrixFull']
    pii = E @ mapping_matrix @ cp.hstack([pi_b, pi_d])
    
    # çº¦æŸæ¡ä»¶
    constraints = []
    
    # 1. è´¨é‡çº¦æŸï¼ˆåªé’ˆå¯¹å‰5ä¸ªlinkï¼‰
    mass_indices = list(range(9, 50, 10))  # link1-link5: [9, 19, 29, 39, 49]
    mass_urdf = np.array([0.607, 0.918, 0.7, 0.359, 0.403])  # å‰5ä¸ªlinkçš„è´¨é‡
    error_range = 0.15  # æ”¾å®½åˆ°15%ä»¥æé«˜æ±‚è§£æˆåŠŸç‡
    mass_upper = mass_urdf * (1 + error_range)
    mass_lower = mass_urdf * (1 - error_range)
    
    print(f"    æ·»åŠ è´¨é‡çº¦æŸï¼ˆå‰5ä¸ªlinkï¼ŒÂ±{error_range*100}%ï¼‰...")
    for i, idx in enumerate(mass_indices):
        constraints.append(pii[idx] >= max(0, mass_lower[i]))
        constraints.append(pii[idx] <= mass_upper[i])
    
    # 2. ç‰©ç†ä¸€è‡´æ€§çº¦æŸ - ä¿®å¤ç‰ˆ
    print("    æ·»åŠ ç‰©ç†ä¸€è‡´æ€§çº¦æŸ...")
    for link_idx in range(6):
        i = link_idx * 10
        
        # æƒ¯æ€§å¼ é‡ (3x3) - ä½¿ç”¨ vstack/hstack
        I_link = cp.vstack([
            cp.hstack([pii[i],     pii[i+1], pii[i+2]]),
            cp.hstack([pii[i+1],   pii[i+3], pii[i+4]]),
            cp.hstack([pii[i+2],   pii[i+4], pii[i+5]])
        ])
        
        # ä¸€é˜¶çŸ© (3,) -> æ˜ç¡®æŒ‡å®š reshape çš„ order
        h_link = pii[i+6:i+9]
        h_link_col = cp.reshape(h_link, (3, 1), order='C')  # (3, 1)
        h_link_row = cp.reshape(h_link, (1, 3), order='C')  # (1, 3)
        
        # è´¨é‡ (æ ‡é‡) -> (1, 1)
        m_link = pii[i+9]
        m_link_reshaped = cp.reshape(m_link, (1, 1))
        
        # æ„å»ºç‰©ç†ä¸€è‡´æ€§çŸ©é˜µ D (4x4)
        # D = [0.5*tr(I)*I_3 - I,  h;
        #      h^T,                m]
        trace_I = cp.trace(I_link)
        
        # ä¸ŠåŠéƒ¨åˆ† (3x4): [0.5*tr(I)*I_3 - I | h]
        upper_left = 0.5 * trace_I * np.eye(3) - I_link  # (3, 3)
        upper_right = h_link_col  # (3, 1)
        upper_part = cp.hstack([upper_left, upper_right])  # (3, 4)
        
        # ä¸‹åŠéƒ¨åˆ† (1x4): [h^T | m]
        lower_left = h_link_row  # (1, 3)
        lower_right = m_link_reshaped  # (1, 1)
        lower_part = cp.hstack([lower_left, lower_right])  # (1, 4)
        
        # å®Œæ•´çš„DçŸ©é˜µ (4x4)
        D_link = cp.vstack([upper_part, lower_part])
        
        # åŠæ­£å®šçº¦æŸ
        constraints.append(D_link >> 0)
    
    # 3. æ‘©æ“¦å‚æ•°çº¦æŸ
    print("    æ·»åŠ æ‘©æ“¦å‚æ•°çº¦æŸ...")
    for i in range(6):
        constraints.append(pi_frctn[3*i] >= 0)      # ç²˜æ€§æ‘©æ“¦ >= 0
        constraints.append(pi_frctn[3*i + 1] >= 0)  # åº“ä¼¦æ‘©æ“¦ >= 0
    
    # ç›®æ ‡å‡½æ•°
    tau_error = cp.norm(Tau - Wb @ cp.hstack([pi_b, pi_frctn]))
    
    use_regularization = (pi_urdf is not None) and (lambda_reg > 0)
    
    if use_regularization:
        # åªå¯¹å‰5ä¸ªlinkï¼ˆå‰50ä¸ªå‚æ•°ï¼‰è¿›è¡Œæ­£åˆ™åŒ–
        # pii[0:50] å¯¹åº” link1-link5 çš„å‚æ•°
        if len(pi_urdf) != 50:
            print(f"  è­¦å‘Š: pi_urdfé•¿åº¦ä¸º{len(pi_urdf)}ï¼ŒæœŸæœ›50ã€‚å°†æˆªæ–­æˆ–å¡«å……ã€‚")
            pi_urdf_padded = np.zeros(50)
            pi_urdf_padded[:min(50, len(pi_urdf))] = pi_urdf[:min(50, len(pi_urdf))]
            pi_urdf = pi_urdf_padded
        
        param_regularization = lambda_reg * cp.norm(pii[:50] - pi_urdf)
        objective = tau_error + param_regularization
        print(f"    ç›®æ ‡ = tauè¯¯å·® + {lambda_reg:.1e} * å‚æ•°æ­£åˆ™åŒ–ï¼ˆä»…å‰5ä¸ªlinkï¼‰")
    else:
        objective = tau_error
        print("    ç›®æ ‡ = tauè¯¯å·® (æ— æ­£åˆ™åŒ–)")
    
    # æ±‚è§£SDP
    print("  æ±‚è§£SDPä¼˜åŒ–é—®é¢˜...")
    
    problem = cp.Problem(cp.Minimize(objective), constraints)
    
    try:
        # å°è¯•ä½¿ç”¨MOSEKæ±‚è§£å™¨
        try:
            result = problem.solve(
                solver=cp.MOSEK,
                verbose=False
            )
            print(f"  âœ“ ä½¿ç”¨MOSEKæ±‚è§£å™¨ (çŠ¶æ€: {problem.status})")
        except:
            # å›é€€åˆ°SCSæ±‚è§£å™¨ï¼Œä½†æé«˜ç²¾åº¦
            print("  MOSEKä¸å¯ç”¨ï¼Œä½¿ç”¨SCSæ±‚è§£å™¨...")
            result = problem.solve(
                solver=cp.SCS,
                verbose=False,
                max_iters=10000,
                eps=1e-6,  # æé«˜ç²¾åº¦ï¼ˆä»1e-4æ”¹ä¸º1e-6ï¼‰
                alpha=1.6,  # æ”¹å–„æ”¶æ•›
                scale=5.0   # æ”¹å–„æ•°å€¼ç¨³å®šæ€§
            )
        
        if problem.status not in ['optimal', 'optimal_inaccurate']:
            print(f" æ±‚è§£çŠ¶æ€: {problem.status}")
            print("  å°è¯•CVXOPTæ±‚è§£å™¨...")
            result = problem.solve(solver=cp.CVXOPT, verbose=False)
        
        if problem.status in ['optimal', 'optimal_inaccurate']:
            print(f"  âœ“ SDPæ±‚è§£æˆåŠŸ! (çŠ¶æ€: {problem.status})")
            if problem.status == 'optimal_inaccurate':
                print("   æ³¨æ„: æ±‚è§£ç²¾åº¦å¯èƒ½ä¸å¤Ÿï¼Œç»“æœå¯èƒ½è½»å¾®è¿åçº¦æŸ")
        else:
            print(f"    æ±‚è§£çŠ¶æ€: {problem.status}")
            print("  ç»“æœå¯èƒ½ä¸å‡†ç¡®")
    
    except Exception as e:
        print(f"  SDPæ±‚è§£å¤±è´¥: {e}")
        raise
    
    # æå–ç»“æœ
    pi_b_SDP = pi_b.value
    pi_frctn_SDP = pi_frctn.value
    pi_d_value = pi_d.value
    
    if pi_b_SDP is None or pi_frctn_SDP is None:
        raise RuntimeError("SDPæ±‚è§£å¤±è´¥ï¼Œæ— æ³•æå–å‚æ•°å€¼")
    
    # è®¡ç®—å®Œæ•´æ ‡å‡†å‚æ•°
    pi_full = E @ mapping_matrix @ np.concatenate([pi_b_SDP, pi_d_value])
    mass_estimated = pi_full[mass_indices]
    
    # éªŒè¯ç»“æœ
    
    tau_pred = Wb @ np.concatenate([pi_b_SDP, pi_frctn_SDP])
    tau_pred_error = np.linalg.norm(Tau - tau_pred)
    rel_tau_error = 100 * tau_pred_error / np.linalg.norm(Tau)
    print(f"  Taué¢„æµ‹è¯¯å·®: {tau_pred_error:.4e} ({rel_tau_error:.2f}%)")
    
    if use_regularization:
        param_deviation = np.linalg.norm(pi_full[:50] - pi_urdf)
        print(f"  å‰5ä¸ªlinkå‚æ•°åç¦»URDF: {param_deviation:.4e}")
    
    # è´¨é‡å¯¹æ¯”ï¼ˆå‰5ä¸ªlinkï¼‰
    print("\n  ä¼°è®¡çš„è¿æ†è´¨é‡ï¼ˆå‰5ä¸ªlinkï¼‰:")
    print("  è¿æ† | URDFå‚è€ƒ | ä¼°è®¡å€¼ | ç›¸å¯¹è¯¯å·®")
    print("  " + "-"*45)
    for i in range(5):  # åªæ˜¾ç¤ºå‰5ä¸ªlink
        rel_error = 100 * (mass_estimated[i] - mass_urdf[i]) / mass_urdf[i]
        print(f"  Link{i+1} | {mass_urdf[i]:7.4f}kg | {mass_estimated[i]:7.4f}kg | {rel_error:+7.2f}%")
    
    # æ£€æŸ¥æƒ¯æ€§çŸ©é˜µï¼ˆå‰5ä¸ªlinkæœ‰æ­£åˆ™åŒ–çº¦æŸï¼‰
    print("\n  æ£€æŸ¥æƒ¯æ€§çŸ©é˜µæ­£å®šæ€§:")
    for link_idx in range(6):
        i = link_idx * 10
        I_val = np.array([
            [pi_full[i],     pi_full[i+1], pi_full[i+2]],
            [pi_full[i+1],   pi_full[i+3], pi_full[i+4]],
            [pi_full[i+2],   pi_full[i+4], pi_full[i+5]]
        ])
        eig_vals = np.linalg.eigvalsh(I_val)
        
        if np.all(eig_vals > -1e-6):
            status = "âœ“"
        else:
            status = "âœ—"
        
        regularized = "ã€æ­£åˆ™åŒ–ã€‘" if link_idx < 5 else "ã€æ— çº¦æŸã€‘"
        print(f"    Link{link_idx+1} {regularized}: {status} (Î»_min = {np.min(eig_vals):.4e})")
    
    return pi_b_SDP, pi_frctn_SDP, pi_full, mass_estimated


# æ•°æ®å¤„ç†å‡½æ•°

def parse_ur_data(path_to_data, idx_start, idx_end):
    import pandas as pd
    
    if not os.path.exists(path_to_data):
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {path_to_data}")
    
    print(f"  ä» {path_to_data} åŠ è½½æ•°æ®...")
    df = pd.read_csv(path_to_data)
    
    # æ£€æŸ¥æ•°æ®èŒƒå›´
    if idx_end >= len(df):
        print(f"  âš ï¸  ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè°ƒæ•´ä¸º: [{ idx_start}, {len(df)-1}]")
        idx_end = len(df) - 1
    
    data = df.iloc[idx_start:idx_end+1]
    
    data_dict = {
        't': data.iloc[:, 0].values,
        'q': data.iloc[:, 1:7].values,
        'qd': data.iloc[:, 7:13].values,
        'i': data.iloc[:, 13:19].values,
    }
    
    data_dict['qd_fltrd'] = data_dict['qd'].copy()
    data_dict['q2d_est'] = np.zeros_like(data_dict['qd'])
    data_dict['i_fltrd'] = data_dict['i'].copy()
    
    print(f"  âœ“ åŠ è½½äº† {len(data_dict['t'])} ä¸ªæ•°æ®ç‚¹")
    return data_dict


def filter_data(data_dict, fs=500.0): 
    from scipy.signal import butter, filtfilt
    
    print(f"  è¿‡æ»¤æ•°æ® (åŸºäº MATLAB é€»è¾‘ï¼Œé‡‡æ ·ç‡ fs={fs} Hz)...")
    
    nyq = 0.5 * fs # å¥ˆå¥æ–¯ç‰¹é¢‘ç‡
    
    # --- 1. é€Ÿåº¦æ»¤æ³¢è®¾è®¡å’Œåº”ç”¨ ---
    
    # MATLAB: FilterOrder=5, HalfPowerFrequency=0.15
    # Pythonçš„ butter å‡½æ•°ç›´æ¥æ¥å—å½’ä¸€åŒ–æˆªæ­¢é¢‘ç‡ (ç›¸å¯¹äºå¥ˆå¥æ–¯ç‰¹é¢‘ç‡)
    normal_cutoff_vel = 0.15 
    N_order = 5 # 5é˜¶æ»¤æ³¢å™¨
    
    # è®¡ç®—æ»¤æ³¢å™¨ç³»æ•°
    b_vel, a_vel = butter(N_order, normal_cutoff_vel, btype='low', analog=False)
    
    # è¿‡æ»¤é€Ÿåº¦
    qd_fltrd = np.zeros_like(data_dict['qd'])
    for i in range(6):
        qd_fltrd[:, i] = filtfilt(b_vel, a_vel, data_dict['qd'][:, i])
    data_dict['qd_fltrd'] = qd_fltrd
    
    # --- 2. ä¼°è®¡åŠ é€Ÿåº¦ï¼šä¸‰ç‚¹ä¸­å¿ƒå·®åˆ† ---
    
    dt = np.mean(np.diff(data_dict['t']))
    if dt <= 0:
        dt = 1.0 / fs
        print(f"  âš ï¸  æ— æ•ˆæ—¶é—´æ­¥é•¿ï¼Œä½¿ç”¨é»˜è®¤å€¼: {dt}s")
    
    q2d_est = np.zeros_like(data_dict['qd_fltrd'])
    N_samples = data_dict['qd_fltrd'].shape[0]
    
    # æ˜¾å¼å®ç° MATLAB ä¸­çš„ä¸‰ç‚¹ä¸­å¿ƒå·®åˆ† (i=2 åˆ° N-1ï¼Œè¾¹ç•Œç‚¹ä¿æŒä¸ºé›¶)
    for i in range(1, N_samples - 1): # Python ç´¢å¼• 1 åˆ° N-2 å¯¹åº” MATLAB ç´¢å¼• 2 åˆ° N-1
       dlta_qd_fltrd =  data_dict['qd_fltrd'][i+1,:] - data_dict['qd_fltrd'][i-1,:]
       dlta_t_msrd = data_dict['t'][i+1] - data_dict['t'][i-1]
       q2d_est[i,:] = dlta_qd_fltrd / dlta_t_msrd

    # æ›¿æ¢ np.gradient çš„ç»“æœ
    data_dict['q2d_est'] = q2d_est
    
    # --- 3. åŠ é€Ÿåº¦æ»¤æ³¢è®¾è®¡å’Œåº”ç”¨ ---
    
    # MATLAB: åŠ é€Ÿåº¦æ»¤æ³¢ä¸é€Ÿåº¦æ»¤æ³¢å‚æ•°ç›¸åŒ
    b_accel = b_vel
    a_accel = a_vel
    
    # è¿‡æ»¤åŠ é€Ÿåº¦
    for i in range(6):
        data_dict['q2d_est'][:, i] = filtfilt(b_accel, a_accel, data_dict['q2d_est'][:, i])
    
    # --- 4. ç”µæµ/åŠ›çŸ©æ»¤æ³¢è®¾è®¡å’Œåº”ç”¨ ---
    
    # MATLAB: FilterOrder=5, HalfPowerFrequency=0.20
    normal_cutoff_curr = 0.20 
    b_curr, a_curr = butter(N_order, normal_cutoff_curr, btype='low', analog=False)
    
    # è¿‡æ»¤ç”µæµ/åŠ›çŸ©
    i_fltrd = np.zeros_like(data_dict['i'])
    for i in range(6):
        i_fltrd[:, i] = filtfilt(b_curr, a_curr, data_dict['i'][:, i])
    data_dict['i_fltrd'] = i_fltrd
    
    print("  âœ“ æ•°æ®è¿‡æ»¤å®Œæˆ")
    return data_dict


def load_urdf_parameters(urdf_path):
    """
    ä»URDFåŠ è½½å‰5ä¸ªlinkçš„å‚è€ƒå‚æ•°
    Returns:
        pi_urdf: (50,) æ•°ç»„ï¼ŒåŒ…å«link1-link5çš„å‚æ•°ï¼ˆæ¯ä¸ªlink 10ä¸ªå‚æ•°ï¼‰
    """
    if not os.path.exists(urdf_path):
        print(f"  âš ï¸  URDFæ–‡ä»¶ä¸å­˜åœ¨: {urdf_path}")
        return np.zeros(50)  # 5ä¸ªlink Ã— 10ä¸ªå‚æ•°/link = 50
    
    try:
        sys.path.insert(0, 'utils')
        from utils.parse_urdf import parse_urdf
        robot = parse_urdf(urdf_path)
        # parse_urdf è¿”å› (10, 5) çš„æ•°ç»„ï¼ˆ5ä¸ªlinkï¼‰
        # éœ€è¦å±•å¹³ä¸º (50,) æŒ‰åˆ—ä¼˜å…ˆï¼ˆFortrané¡ºåºï¼‰ä»¥åŒ¹é…MATLABæ ¼å¼
        pi_urdf_5links = robot['pi'].flatten('F')  # 'F' = Fortran/åˆ—ä¼˜å…ˆé¡ºåº
        print(f"  âœ“ ä»URDFåŠ è½½äº†å‰5ä¸ªlinkçš„ {len(pi_urdf_5links)} ä¸ªå‚è€ƒå‚æ•°")
        return pi_urdf_5links
    except Exception as e:
        print(f"  âš ï¸  æ— æ³•ä»URDFåŠ è½½å‚æ•°: {e}")
        return np.zeros(50)


def print_estimation_summary(sol, Tau, tau_pred):
    
    
    print(f"  åŸºç¡€å‚æ•°æ•°é‡: {len(sol['pi_b'])}")
    print(f"  æ‘©æ“¦å‚æ•°æ•°é‡: {len(sol['pi_fr'])}")
    
    residual = Tau - tau_pred
    rmse = np.sqrt(np.mean(residual**2))
    r_squared = 1 - np.sum(residual**2) / np.sum((Tau - np.mean(Tau))**2)
    
    print(f"\n  æ‹Ÿåˆè´¨é‡:")
    print(f"    RMSE: {rmse:.4e}")
    print(f"    RÂ²: {r_squared:.6f}")
    
    print(f"\n  å‚æ•°ç»Ÿè®¡:")
    print(f"    å¹³å‡ç›¸å¯¹æ ‡å‡†å·®: {np.mean(sol['rel_std']):.2f}%")
    print(f"    æœ€å¤§ç›¸å¯¹æ ‡å‡†å·®: {np.max(sol['rel_std']):.2f}%")
    
    if sol['masses'] is not None:
        print(f"\n  ä¼°è®¡çš„æ€»è´¨é‡: {np.sum(sol['masses']):.4f} kg")
    


# ä¸»å‡½æ•°

def estimate_dynamic_params(path_to_data, idx, drv_gains, baseQR, method='OLS',
                           lambda_reg=1e-3, urdf_path=None):
    """
    
    Args:
        path_to_data: æ•°æ®æ–‡ä»¶è·¯å¾„
        idx: æ•°æ®ç´¢å¼•èŒƒå›´ [start, end]
        drv_gains: é©±åŠ¨å¢ç›Š
        baseQR: QRåˆ†è§£ç»“æœ
        method: 'OLS', 'PC-OLS', æˆ– 'PC-OLS-REG'
        lambda_reg: æ­£åˆ™åŒ–ç³»æ•°
        urdf_path: URDFæ–‡ä»¶è·¯å¾„
    
    Returns:
        sol: ä¼°è®¡ç»“æœå­—å…¸
    """
    
    print(f"åŠ¨åŠ›å­¦å‚æ•°ä¼°è®¡ - æ–¹æ³•: {method}")
    
    # 1. åŠ è½½å’Œå¤„ç†æ•°æ®
    print("\næ­¥éª¤ 1/4: åŠ è½½å’Œå¤„ç†æ•°æ®...")
    idntfcn_traj = parse_ur_data(path_to_data, idx[0], idx[1])
    idntfcn_traj = filter_data(idntfcn_traj)
    
    # 2. æ„å»ºè§‚æµ‹çŸ©é˜µ
    print("\næ­¥éª¤ 2/4: æ„å»ºè§‚æµ‹çŸ©é˜µ...")
    Tau, Wb = build_observation_matrices(idntfcn_traj, baseQR, drv_gains)
    print(f"  è§‚æµ‹çŸ©é˜µ Wb å½¢çŠ¶: {Wb.shape}")
    print(f"  åŠ›çŸ©å‘é‡ Tau å½¢çŠ¶: {Tau.shape}")
    n_base = baseQR['numberOfBaseParameters']
    n_params = n_base + 18
    
    # 3. ä¼°è®¡å‚æ•°
    print(f"\næ­¥éª¤ 3/4: å‚æ•°ä¼°è®¡ ({method})...")
    
    sol = {}
    
    if method == 'OLS':
        pi_b, pi_fr = ordinary_least_square_estimation(Tau, Wb, baseQR)
        sol['pi_b'] = pi_b
        sol['pi_fr'] = pi_fr
        sol['pi_s'] = None
        sol['masses'] = None
        
    elif method == 'PC-OLS':
        pi_b, pi_fr, pi_s, masses = physically_consistent_estimation(
            Tau, Wb, baseQR, pi_urdf=None, lambda_reg=0
        )
        sol['pi_b'] = pi_b
        sol['pi_fr'] = pi_fr
        sol['pi_s'] = pi_s
        sol['masses'] = masses
        
    elif method == 'PC-OLS-REG':
        if urdf_path is None:
            raise ValueError("PC-OLS-REGæ–¹æ³•éœ€è¦æä¾›urdf_pathå‚æ•°")
        
        print(f"  åŠ è½½URDFå‚è€ƒå‚æ•°: {urdf_path}")
        pi_urdf = load_urdf_parameters(urdf_path)
        
        pi_b, pi_fr, pi_s, masses = physically_consistent_estimation(
            Tau, Wb, baseQR, pi_urdf, lambda_reg
        )
        sol['pi_b'] = pi_b
        sol['pi_fr'] = pi_fr
        sol['pi_s'] = pi_s
        sol['masses'] = masses
        
    else:
        raise ValueError(f"æœªçŸ¥æ–¹æ³•: {method}. å¯é€‰: 'OLS', 'PC-OLS', 'PC-OLS-REG'")
    
    # 4. ç»Ÿè®¡åˆ†æ
    print("\næ­¥éª¤ 4/4: ç»Ÿè®¡åˆ†æ...")
    
    tau_pred = Wb @ np.concatenate([sol['pi_b'], sol['pi_fr']])
    residual = Tau - tau_pred
    
    n_samples = Wb.shape[0]
    n_params = Wb.shape[1]
    sqrd_sigma_e = np.linalg.norm(residual)**2 / (n_samples - n_params)
    
    try:
        Wb_inv = inv(Wb.T @ Wb)
        Cpi = sqrd_sigma_e * Wb_inv
        sol['std'] = np.sqrt(np.diag(Cpi))
    except np.linalg.LinAlgError:
        print("  âš ï¸  åæ–¹å·®çŸ©é˜µè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨è¿‘ä¼¼å€¼")
        sol['std'] = np.ones(len(sol['pi_b']) + len(sol['pi_fr']))
    
    params_all = np.concatenate([sol['pi_b'], sol['pi_fr']])
    # é¿å…é™¤ä»¥é›¶
    params_all_safe = np.where(np.abs(params_all) < 1e-10, 1e-10, params_all)
    sol['rel_std'] = 100 * sol['std'] / np.abs(params_all_safe)
    
    print_estimation_summary(sol, Tau, tau_pred)
    
    print("âœ… å‚æ•°ä¼°è®¡å®Œæˆ!")
    
    return sol


def main():
    mat_filename_standard = 'models/baseQR_standard.mat'
    
    print(f"å°è¯•ä» MATLAB æ–‡ä»¶åŠ è½½åŸºç¡€å‚æ•°: {mat_filename_standard}")
    
    # ===================================================================
    # ã€å·²ä¿®æ”¹ï¼šä½¿ç”¨ h5py æ›¿æ¢ loadmat æ¥è¯»å– v7.3 æ ¼å¼æ–‡ä»¶ã€‘
    # ===================================================================
    try:
        if not os.path.exists(mat_filename_standard):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {mat_filename_standard}")
            
        # 1. ä½¿ç”¨ h5py.File è¯»å– HDF5 æ–‡ä»¶
        with h5py.File(mat_filename_standard, 'r') as f:
            print("    âœ“ æ­£åœ¨ä½¿ç”¨ h5py è¯»å– HDF5 æ ¼å¼...")
            
            # è®¿é—® baseQR ç»“æ„ä½“å¯¹åº”çš„ HDF5 Group
            baseQR_group = f['baseQR']
            
            # 2. ä» HDF5 Group ä¸­æå–æ•°æ®ï¼Œå¹¶å¤„ç†ç»´åº¦å’Œè½¬ç½® (MATLAB åˆ—ä¼˜å…ˆ vs Python è¡Œä¼˜å…ˆ)
            
            # numberOfBaseParameters: æ ‡é‡
            bb = np.array(baseQR_group['numberOfBaseParameters']).flatten()[0]
            
            # permutationMatrix: éœ€è¦è½¬ç½® (.T)
            E_full = np.array(baseQR_group['permutationMatrix']).T
            
            # beta: éœ€è¦è½¬ç½® (.T)
            beta = np.array(baseQR_group['beta']).T
            
            # motorDynamicsIncluded: æ ‡é‡
            motorDynamicsIncluded = bool(np.array(baseQR_group['motorDynamicsIncluded']).flatten()[0])

            # 3. å°è£…åˆ° Python å­—å…¸
            baseQR = {
                'numberOfBaseParameters': int(bb),
                'permutationMatrixFull': E_full,
                'beta': beta,
                'motorDynamicsIncluded': motorDynamicsIncluded
            }

        # --- åŸå§‹çš„ç»´åº¦æ£€æŸ¥ä»ç„¶éå¸¸é‡è¦ ---
        if baseQR['beta'].ndim == 1:
            # å¦‚æœ beta æ˜¯ (N,) å‘é‡ï¼Œç¡®ä¿å®ƒæ˜¯ (N, 1) çš„åˆ—å‘é‡
            baseQR['beta'] = baseQR['beta'].reshape(-1, 1)

        print(f"âœ… æˆåŠŸä» {mat_filename_standard} åŠ è½½åŸºç¡€å‚æ•°ã€‚")
        print(f"   åŸºç¡€å‚æ•°æ•°é‡ N_b: {baseQR['numberOfBaseParameters']}")
        
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {mat_filename_standard}")
        print("è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œå¹¶ç¡®ä¿å·²è¿è¡Œ MATLAB è„šæœ¬ base_params_qr.m ç”Ÿæˆæ–‡ä»¶ã€‚")
        sys.exit(1)
    except Exception as e:
        # å¦‚æœæ˜¯æƒé™é—®é¢˜ã€h5pyå¯¼å…¥é—®é¢˜æˆ–è§£æé”™è¯¯ï¼Œéƒ½å¯ä»¥åœ¨è¿™é‡Œæ•è·
        print(f"âŒ é”™è¯¯: åŠ è½½æˆ–è§£æ MATLAB HDF5 æ–‡ä»¶å¤±è´¥: {e}")
        # æç¤ºç”¨æˆ·å¯èƒ½éœ€è¦å®‰è£… h5py æˆ–æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        if 'h5py' not in sys.modules:
            print("æç¤º: æ‚¨çš„é”™è¯¯å¯èƒ½æ˜¯ç¼ºå°‘ 'h5py' åº“ã€‚è¯·è¿è¡Œ 'pip install h5py'ã€‚")
        print("è¯·ç¡®ä¿ MATLAB æ–‡ä»¶å·²ä½¿ç”¨ '-v7.3' é€‰é¡¹ä¿å­˜ã€‚")
        sys.exit(1)
    # ===================================================================
    # ... (å‡½æ•°çš„å…¶ä½™éƒ¨åˆ†ä¿æŒä¸å˜)
    
    # å‚æ•°è®¾ç½®
    drv_gains = np.ones(6)
    idx = [0, 2500]
    
    data_path = 'vali.csv'
    urdf_path = 'models/mjcf/manipulator/airbot_play_force/_play_force.urdf'

    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_path):
        print(f"âŒ é”™è¯¯: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        sys.exit(1)

    # æ–¹æ³•1: OLS
    print("\n" + "ğŸ”¹"*35)
    print("è¿è¡Œæ–¹æ³• 1: OLS")
    print("ğŸ”¹"*35)
    sol_ols = estimate_dynamic_params(
        path_to_data=data_path,
        idx=idx,
        drv_gains=drv_gains,
        baseQR=baseQR,
        method='OLS'
    )
    
    # æ–¹æ³•2: PC-OLS-REG (æ¨è)
    if os.path.exists(urdf_path):
        print("\n" + "ğŸ”¹"*35)
        print("è¿è¡Œæ–¹æ³• 2: PC-OLS-REG")
        print("ğŸ”¹"*35)
        sol_pc = estimate_dynamic_params(
            path_to_data=data_path,
            idx=idx,
            drv_gains=drv_gains,
            baseQR=baseQR,
            method='PC-OLS-REG',
            lambda_reg=1e-3,
            urdf_path=urdf_path
        )
    else:
        print(f"\n URDFæ–‡ä»¶ä¸å­˜åœ¨: {urdf_path}")
        print("  è·³è¿‡PC-OLS-REG")
        sol_pc = None
    
    # ä¿å­˜ç»“æœ
    with open('estimation_results.pkl', 'wb') as f:
        pickle.dump({'sol_ols': sol_ols, 'sol_pc': sol_pc}, f)
    
    print("\næ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° estimation_results.pkl")


if __name__ == "__main__":
    # ç¡®ä¿pandaså·²å®‰è£…ï¼Œå› ä¸ºparse_ur_dataä¾èµ–å®ƒ
    try:
        import pandas as pd
    except ImportError:
        print("âŒ é”™è¯¯: éœ€è¦å®‰è£… Pandas åº“: pip install pandas")
        sys.exit(1)
        
    main()